% Sample tex file for usage of iidef.sty
% Homework template for Inference and Information
% UPDATE: October 12, 2017 by Xiangxiang
% UPDATE: 22/03/2018 by zhaofeng-shu33
\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amsthm}
% amsmath: equation*, amssymb: mathbb, amsthm: proof
\usepackage{moreenum}
\usepackage{mathtools}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % toprule
\usepackage[mathcal]{eucal}
\usepackage{dsfont}

\usepackage{setspace}  
\setstretch{1.6}








\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}[definition]{Example}
\newtheorem{exercise}[definition]{Exercise}
\newtheorem{remark}[definition]{Remark}
\newtheorem{observation}[definition]{Observation}
\newtheorem{assumption}[definition]{Assumption}
\newtheorem{convention}[definition]{Convention}
\newtheorem{priniple}[definition]{Principle}
\newtheorem{notation}[definition]{Notation}
\newtheorem*{axiom}{Axiom}
\newtheorem{coa}[definition]{Theorem}
\newtheorem{srem}[definition]{$\star$ Remark}
\newtheorem{seg}[definition]{$\star$ Example}
\newtheorem{sexe}[definition]{$\star$ Exercise}
\newtheorem{sdf}[definition]{$\star$ Definition}
\newtheorem{question}{Question}




\newtheorem{problem}{Problem}
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{rprob}[problem]{\color{red} Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}



\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{Conclusion}[definition]{Conclusion}
\newtheorem{thd}[definition]{Theorem-Definition}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{sthm}[definition]{$\star$ Theorem}
\newtheorem{slm}[definition]{$\star$ Lemma}
\newtheorem{claim}[definition]{Claim}
\newtheorem{spp}[definition]{$\star$ Proposition}
\newtheorem{scorollary}[definition]{$\star$ Corollary}


\newtheorem{condition}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecondition}{\Alph{condition}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}
%write mathscr Hom (and so on) 

\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}

\newcommand{\vol}{\text{\Fontlukas V}}
\newcommand{\dvol}{d~\text{\Fontlukas V}}
% perfect Vol symbol

\usepackage{aurical}








\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\cond}[1]{\mathrm{cond}_{#1}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\Dom}{\mathrm{Dom}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathop\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\eps}{\varepsilon}
\newcommand{\Vol}{\mathrm{Vol}}
\newcommand{\LSC}{\mathrm{LSC}}
\newcommand{\USC}{\mathrm{USC}}
\newcommand{\Ess}{\mathrm{Rng}^{\mathrm{ess}}}
\newcommand{\Jbf}{\mathbf{J}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Lin}{\mathrm{Lin}}
\newcommand{\ALin}{\mathrm{ALin}}
\newcommand{\bwn}{\bigwedge\nolimits}
\newcommand{\nbf}{\mathbf n}
\newcommand{\dive}{\mathrm{div}}
\newcommand{\<}{\left<}
\renewcommand{\>}{\right>}
\renewcommand{\Ebb}{\mathop\mathbb{E}}


\usepackage{algorithm}
\usepackage{algorithmic}


\newcommand{\OPT}{\mathrm{OPT}}



\numberwithin{equation}{problem}
% count the eqation by section countation


\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\img}{Im}
\DeclareMathOperator{\dd}{d\!}
\newcommand{\ie}{ \textit{ i.e. } }
\newcommand{\st}{ \textit{ s.t. }}




\usepackage[thehwcnt = 5]{iidef}
\usepackage{tikz} % Required for tikzpicture environment
\thecourseinstitute{Tsinghua University}
\thecoursename{Discrete Optimistic}
\theterm{Fall 2024}
\hwname{Homework}
\usepackage{geometry}
\geometry{left=1.5cm,right=1.5cm,top=2.5cm,bottom=2.5cm}

\begin{document}

\courseheader
\name{Lin Zejin}
\rule{\textwidth}{1pt}
\begin{itemize}
\item {\bf Collaborators: \/}
  I finish this homework by myself. 
%   If you finish your homework all by yourself, make a similar statement. If you get help from others in finishing your homework, state like this:
%   \begin{itemize}
%   \item 1.2 (b) was solved with the help from \underline{\hspace{3em}}.
%   \item Discussion with \underline{\hspace{3em}} helped me finishing 1.3.
%   \end{itemize}
\end{itemize}
\rule{\textwidth}{1pt}

\vspace{2em}


\sloppy
\pagenumbering{arabic}

\begin{problem}
    (a)\[\lambda(G)=\lambda_{\mathrm{min}}(I+\frac{1}{d}A)=\min_{\vec{x}}\frac{\vec{x}^T(I+\frac{1}{d}A)\vec{x}}{\vec{x}^T\vec{x}}=\min_{\vec{x}}\frac{\frac{1}{d}\sum_{((i,j)\in E)}(x_i+x_j)^2}{\sum_{i=1}^nx_i^2} \leq \min_{\vec{y}\in \{0,1,-1\}^n}\frac{\frac{1}{d}\sum_{((i,j)\in E)}(x_i+x_j)^2}{\sum_{i=1}^nx_i^2}=\beta(G)\]

    For  $ \vec{x} $ such that 
    \[\lambda(G)=\frac{1}{d}\cdot\frac{\sum_{(i,j)\in E}(x_i+x_j)^2}{\sum_{i=1}^nx_i^2}\] 

    The algorithm  $ \mathcal{A} $ is defined as follows:
    \begin{enumerate}
        \item Randomly sample  $ t\in [0,1] $.
        \item Normalize  $ \|\vec{x}\|=1 $.
        \item Let  $ y_i=\begin{cases}
            1&x_i>t\\
            -1&x_i<-t\\
            0&\text{otherwise}
        \end{cases} $.
    \end{enumerate} 
    Then 
    \[\Ebb_t\beta(G)=\Ebb_t\frac{1}{d}\cdot\frac{\sum_{(i,j)\in E}(y_i+y_j)^2}{\sum_{i=1}^ny_i^2}=\frac{1}{d}\cdot\frac{\sum_{(i,j)\in E}(x_i+x_j)^2}{\sum_{i=1}^nx_i^2}=\lambda(G) \leq \sqrt{2\lambda(G)}\]

    So the rounding algorithm will return a feasible solution efficiently.

    As a result,
    \[\beta(G) \leq \sqrt{2\lambda(G)}\]
    (b)

\end{problem}


\begin{problem}
    (a) In a connected component with diameter less than  $ \frac{1}{10}d $, each pair of elements in the component should differ at most  $ \frac{1}{10}d $.
    
    Then the total size of the component is less than 
    \[2^\frac{d}{10}\cdot\binom{\frac{d}{10}}{d}\overset{Stirling}{<}2^{0.8d}\]
    Therefore, by isoperimetric inequality, 
    \[\text{the number of edges cut}=\frac{1}{2}\sum_{A:\text{connected component}}|\mathrm{edges}(A,\bar{A})| \geq\sum_A |A|(d-\log_2|A|) \geq \sum_A\frac{1}{10}d|A|=O(n\log n)\]

\end{problem}
\begin{problem}
    
\end{problem}

\begin{problem}
    
\end{problem}
\begin{problem}
    
\end{problem}
\begin{problem}
    
\end{problem}
\begin{problem}
    (a) They are actually all Fourier basis  $ \pm\chi_S $, including the constant function.

    (b) 
    \[\{f:\{\pm 1\}^n\rightarrow \{\pm 1\}:|\mathcal{S}|=k\}=\{\sum_{i=1}^k\pm \chi_{S_i}:S_i\subset [n] \text{ different}\}\] 

    (c) For all  $ S $ odd,  $ \chi_S $ satisfies  $ \chi_S(\vec{x})=-\chi_S(\vec{x}) $. As a result, those functions  $ f $ are odd. Conversely, if a function is odd, then 
    \[f(-\vec{x})=\sum_{S\subset [n]}\hat{f}(S)\chi_S(-\vec{x})=-f(\vec{x})=-\sum_{S\subset [n]}\hat{f}(S)\chi_S(\vec{x})\]
    Therefore,   its support $   \mathcal{S}   $ should contain only  $ S $ with odd elements.      
\end{problem}
\begin{problem}
    (a) 

    WLOG we assume  $ g $ is the subfunction of  $ f $ gotten by fixing  $ x_1=x_2=\cdots=x_c=1 $.    
    
    \[\Ebb_{\vec{x},x_1=x_2=\cdots=x_c=1}f(\vec{x})=\Ebb_{\vec{x}}f(\vec{x})\prod_{i=1}^c(x_i+1)=\sum_{S\subset [c]}\Ebb_{\vec{x}}f(\vec{x})\chi_S(\vec{x})=\sum_{S\subset [c]}\hat{f}(S)\]
    is within an additive  $ \pm2^c\sqrt{\epsilon} $   of the bias  $ \dps\Ebb_{\vec{x}}f(\vec{x})=\hat{f}(\emptyset) $, since  $ \hat{f}(S) \leq \sqrt{\epsilon} $ for all  $ S\subset [c] $.
    
    (b) The hyperthesis implies that for all  $ \vec{y}\in \{\pm 1\}^c $, 
    \[\Ebb_{\vec{x}}f(\vec{x})\prod_{i=1}^c(x_i+y_i)=\sum_{S\subset [c]}\hat{f}(S)\chi_S(\vec{y})\]
    is within an additive  $ \pm \sqrt{\epsilon} $ of the bias  $ \hat{f}(\emptyset) $.
    Then 
    \[h(\vec{y})=\sum_{S\subset [c],S\neq \emptyset}\hat{f}(S)\chi_S(\vec{y})\]
    satisfies that 
    \[|h(\vec{y})| \leq \sqrt{\epsilon},\,\forall \vec{y}\]
    So 
    \[\epsilon \geq \Ebb_{\vec{y}}h(\vec{y})^2=\sum_{S\subset [c]}\hat{h}(S)^2=\sum_{S\subset [c],S\neq \emptyset}\hat{f}(S)^2\] 
    
    Therefore  $ \forall S\subset [c],|S|>0 $,  $ \hat{f}(S)^2 \leq \epsilon $. Similarly, one can prove it for all  $ |S| \leq c<\frac{1}{\delta} $.
    
    So  $ f $ is  $ (\epsilon,\delta) $-quasirandom.
    
    (c) The bias of  $ f $ is  $ 0 $. By fixing  $ c $ bits, the bias of  $ g $ is at most 
    \[\dps\frac{\sum_{-c \leq t-(n-t) \leq c}\binom{t}{n}}{2^n}\]
    In particular, if  $ c=1 $, \ie  $ 1>\delta>\frac{1}{2} $, we have the bias of  $ g $ is at most   
    \[\frac{\binom{\frac{n-1}{2}}{n}}{2^n} \geq \sqrt{\frac{2}{\pi n}}\]
    So it is  $ (\sqrt{\frac{2}{\pi n}},\frac{1}{2}) $-quasirandom         
\end{problem}
\newcommand{\Inf}{\mathrm{Inf}}
\begin{problem}
    (a) In the lecture we have proved that 
    \[\Inf_i(f)=\sum_{S\ni i}\hat{f}(S)^2\]
    Then 
    \[\Inf(f)=\sum_{i=1}^n\sum,_{S\ni i}\hat{f}(S)^2=\sum_{S\subset [n]}|S|\hat{f}(S)^2\]


    (b)  $ \Ebb_{\vec{x}}f(\vec{x})=\hat{f}(\emptyset) $. Therefore, 
    \[\mathrm{Var}(f)=\Ebb_{\vec{x}}f(\vec{x})^2-\left(\Ebb_{\vec{x}}f(\vec{x})\right)^2=\sum_{S\subset [n]}\hat{f}(S)^2-\hat{f}(\emptyset)^2=\sum_{S\neq \emptyset}\hat{f}(S)^2\] 

    (c) Define  $ f(x)=\begin{cases}
        1&x\in A\\
        -1&x\in \bar{A}
    \end{cases} $. 

    Then  \[\dps\mathrm{Var}(f)=\Ebb_{\vec{x}}f(\vec{x})^2-\left(\Ebb_{\vec{x}}f(\vec{x})\right)^2=1-\left(1-\frac{2|A|}{2^n}\right)^2=\frac{|A|}{2^{n-2}}-\frac{|A|^2}{2^{2n-2}}\]
    \[|\mathrm{edges}(A,\bar{A})|=\sum_{i=1}^n 2^{n-1}\Inf_i(f)=2^{n-1}\Inf(f) \geq 2^{n-1}\mathrm{Var}(f)=2|A|(1-\frac{|A|}{2^{n}})\]
\end{problem}

\begin{problem}
    Let
\[
S = \sum_{j=1}^n a_j x_j
\]
where $x_j$ are independent uniform random signs. Then
\[
\operatorname{Inf}_i(f) = \Pr\left[ f(x) \neq f(x^{\oplus i}) \right] = \Pr\left[ S \cdot (S - 2 a_i x_i ) < 0 \right].
\]

This event occurs if and only if $|S| \le 2 |a_i|$. Therefore,
\[
\operatorname{Inf}_i(f) = \Pr\left[ |S| \le 2 |a_i| \right].
\]

Since $\operatorname{Var}(S) = \sum_j a_j^2 = 1$, $S$ is a sum with variance $1$. By the Berry-Essen inequality,
\[
\Pr\left[ |S| \le t \right] \le O\left( t + \tau \right).
\]

Setting $t = 2 |a_i|$, we obtain
\[
\operatorname{Inf}_i(f) \le O\left( |a_i| + \tau \right).
\]

Since $|a_i| \le \tau$, this gives
\[
\operatorname{Inf}_i(f) \le O(\tau).
\]
\hfill $\Box$
\end{problem}
\end{document}
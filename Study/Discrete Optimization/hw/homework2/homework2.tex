% Sample tex file for usage of iidef.sty
% Homework template for Inference and Information
% UPDATE: October 12, 2017 by Xiangxiang
% UPDATE: 22/03/2018 by zhaofeng-shu33
\documentclass[a4paper]{article}
\usepackage[T1]{fontenc}
\usepackage{amsmath, amssymb, amsthm}
% amsmath: equation*, amssymb: mathbb, amsthm: proof
\usepackage{moreenum}
\usepackage{mathtools}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subcaption}
\usepackage{booktabs} % toprule
\usepackage[mathcal]{eucal}
\usepackage{dsfont}

\usepackage{setspace}  
\setstretch{1.6}








\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\newtheorem{example}[definition]{Example}
\newtheorem{exercise}[definition]{Exercise}
\newtheorem{remark}[definition]{Remark}
\newtheorem{observation}[definition]{Observation}
\newtheorem{assumption}[definition]{Assumption}
\newtheorem{convention}[definition]{Convention}
\newtheorem{priniple}[definition]{Principle}
\newtheorem{notation}[definition]{Notation}
\newtheorem*{axiom}{Axiom}
\newtheorem{coa}[definition]{Theorem}
\newtheorem{srem}[definition]{$\star$ Remark}
\newtheorem{seg}[definition]{$\star$ Example}
\newtheorem{sexe}[definition]{$\star$ Exercise}
\newtheorem{sdf}[definition]{$\star$ Definition}
\newtheorem{question}{Question}




\newtheorem{problem}{Problem}
%\renewcommand*{\theprob}{{\color{red}\arabic{section}.\arabic{prob}}}
\newtheorem{rprob}[problem]{\color{red} Problem}
%\renewcommand*{\thesprob}{{\color{red}\arabic{section}.\arabic{sprob}}}
% \newtheorem{ssprob}[prob]{$\star\star$ Problem}



\theoremstyle{plain}
\newtheorem{theorem}[definition]{Theorem}
\newtheorem{Conclusion}[definition]{Conclusion}
\newtheorem{thd}[definition]{Theorem-Definition}
\newtheorem{proposition}[definition]{Proposition}
\newtheorem{corollary}[definition]{Corollary}
\newtheorem{lemma}[definition]{Lemma}
\newtheorem{sthm}[definition]{$\star$ Theorem}
\newtheorem{slm}[definition]{$\star$ Lemma}
\newtheorem{claim}[definition]{Claim}
\newtheorem{spp}[definition]{$\star$ Proposition}
\newtheorem{scorollary}[definition]{$\star$ Corollary}


\newtheorem{condition}{Condition}
\newtheorem{Mthm}{Main Theorem}
\renewcommand{\thecondition}{\Alph{condition}} % "letter-numbered" theorems
\renewcommand{\theMthm}{\Alph{Mthm}} % "letter-numbered" theorems


%\substack   multiple lines under sum
%\underset{b}{a}   b is under a


% Remind: \overline{L_0}



\usepackage{calligra}
\DeclareMathOperator{\shom}{\mathscr{H}\text{\kern -3pt {\calligra\large om}}\,}
\DeclareMathOperator{\sext}{\mathscr{E}\text{\kern -3pt {\calligra\large xt}}\,}
\DeclareMathOperator{\Rel}{\mathscr{R}\text{\kern -3pt {\calligra\large el}~}\,}
\DeclareMathOperator{\sann}{\mathscr{A}\text{\kern -3pt {\calligra\large nn}}\,}
\DeclareMathOperator{\send}{\mathscr{E}\text{\kern -3pt {\calligra\large nd}}\,}
\DeclareMathOperator{\stor}{\mathscr{T}\text{\kern -3pt {\calligra\large or}}\,}
%write mathscr Hom (and so on) 

\usepackage{aurical}
\DeclareMathOperator{\VVir}{\text{\Fontlukas V}\text{\kern -0pt {\Fontlukas\large ir}}\,}

\newcommand{\vol}{\text{\Fontlukas V}}
\newcommand{\dvol}{d~\text{\Fontlukas V}}
% perfect Vol symbol

\usepackage{aurical}








\newcommand{\fk}{\mathfrak}
\newcommand{\mc}{\mathcal}
\newcommand{\wtd}{\widetilde}
\newcommand{\wht}{\widehat}
\newcommand{\wch}{\widecheck}
\newcommand{\ovl}{\overline}
\newcommand{\udl}{\underline}
\newcommand{\tr}{\mathrm{t}} %transpose
\newcommand{\Tr}{\mathrm{Tr}}
\newcommand{\End}{\mathrm{End}} %endomorphism
\newcommand{\idt}{\mathbf{1}}
\newcommand{\id}{\mathrm{id}}
\newcommand{\Hom}{\mathrm{Hom}}
\newcommand{\cond}[1]{\mathrm{cond}_{#1}}
\newcommand{\Conf}{\mathrm{Conf}}
\newcommand{\Res}{\mathrm{Res}}
\newcommand{\res}{\mathrm{res}}
\newcommand{\KZ}{\mathrm{KZ}}
\newcommand{\ev}{\mathrm{ev}}
\newcommand{\coev}{\mathrm{coev}}
\newcommand{\opp}{\mathrm{opp}}
\newcommand{\Rep}{\mathrm{Rep}}
\newcommand{\Dom}{\mathrm{Dom}}
\newcommand{\loc}{\mathrm{loc}}
\newcommand{\con}{\mathrm{c}}
\newcommand{\uni}{\mathrm{u}}
\newcommand{\ssp}{\mathrm{ss}}
\newcommand{\di}{\slashed d}
\newcommand{\Diffp}{\mathrm{Diff}^+}
\newcommand{\Diff}{\mathrm{Diff}}
\newcommand{\PSU}{\mathrm{PSU}(1,1)}
\newcommand{\Vir}{\mathrm{Vir}}
\newcommand{\Witt}{\mathscr W}
\newcommand{\Span}{\mathrm{Span}}
\newcommand{\pri}{\mathrm{p}}
\newcommand{\ER}{E^1(V)_{\mathbb R}}
\newcommand{\prth}[1]{( {#1})}
\newcommand{\bk}[1]{\langle {#1}\rangle}
\newcommand{\bigbk}[1]{\big\langle {#1}\big\rangle}
\newcommand{\Bigbk}[1]{\Big\langle {#1}\Big\rangle}
\newcommand{\biggbk}[1]{\bigg\langle {#1}\bigg\rangle}
\newcommand{\Biggbk}[1]{\Bigg\langle {#1}\Bigg\rangle}
\newcommand{\GA}{\mathscr G_{\mathcal A}}
\newcommand{\vs}{\varsigma}
\newcommand{\Vect}{\mathrm{Vec}}
\newcommand{\Vectc}{\mathrm{Vec}^{\mathbb C}}
\newcommand{\scr}{\mathscr}
\newcommand{\sjs}{\subset\joinrel\subset}
\newcommand{\Jtd}{\widetilde{\mathcal J}}
\newcommand{\gk}{\mathfrak g}
\newcommand{\hk}{\mathfrak h}
\newcommand{\xk}{\mathfrak x}
\newcommand{\yk}{\mathfrak y}
\newcommand{\zk}{\mathfrak z}
\newcommand{\pk}{\mathfrak p}
\newcommand{\hr}{\mathfrak h_{\mathbb R}}
\newcommand{\Ad}{\mathrm{Ad}}
\newcommand{\DHR}{\mathrm{DHR}_{I_0}}
\newcommand{\Repi}{\mathrm{Rep}_{\wtd I_0}}
\newcommand{\im}{\mathbf{i}}
\newcommand{\Co}{\complement}
%\newcommand{\Cu}{\mathcal C^{\mathrm u}}
\newcommand{\RepV}{\mathrm{Rep}^\uni(V)}
\newcommand{\RepA}{\mathrm{Rep}(\mathcal A)}
\newcommand{\RepN}{\mathrm{Rep}(\mathcal N)}
\newcommand{\RepfA}{\mathrm{Rep}^{\mathrm f}(\mathcal A)}
\newcommand{\RepAU}{\mathrm{Rep}^\uni(A_U)}
\newcommand{\RepU}{\mathrm{Rep}^\uni(U)}
\newcommand{\RepL}{\mathrm{Rep}^{\mathrm{L}}}
\newcommand{\HomL}{\mathrm{Hom}^{\mathrm{L}}}
\newcommand{\EndL}{\mathrm{End}^{\mathrm{L}}}
\newcommand{\Bim}{\mathrm{Bim}}
\newcommand{\BimA}{\mathrm{Bim}^\uni(A)}
%\newcommand{\shom}{\scr Hom}
\newcommand{\divi}{\mathrm{div}}
\newcommand{\sgm}{\varsigma}
\newcommand{\SX}{{S_{\fk X}}}
\newcommand{\DX}{D_{\fk X}}
\newcommand{\mbb}{\mathbb}
\newcommand{\mbf}{\mathbf}
\newcommand{\bsb}{\boldsymbol}
\newcommand{\blt}{\bullet}
\newcommand{\Vbb}{\mathbb V}
\newcommand{\Ubb}{\mathbb U}
\newcommand{\Xbb}{\mathbb X}
\newcommand{\Kbb}{\mathbb K}
\newcommand{\Abb}{\mathbb A}
\newcommand{\Wbb}{\mathbb W}
\newcommand{\Mbb}{\mathbb M}
\newcommand{\Gbb}{\mathbb G}
\newcommand{\Cbb}{\mathbb C}
\newcommand{\Nbb}{\mathbb N}
\newcommand{\Zbb}{\mathbb Z}
\newcommand{\Qbb}{\mathbb Q}
\newcommand{\Pbb}{\mathbb P}
\newcommand{\Rbb}{\mathbb R}
\newcommand{\Ebb}{\mathbb E}
\newcommand{\Dbb}{\mathbb D}
\newcommand{\Hbb}{\mathbb H}
\newcommand{\cbf}{\mathbf c}
\newcommand{\Rbf}{\mathbf R}
\newcommand{\wt}{\mathrm{wt}}
\newcommand{\Lie}{\mathrm{Lie}}
\newcommand{\btl}{\blacktriangleleft}
\newcommand{\btr}{\blacktriangleright}
\newcommand{\svir}{\mathcal V\!\mathit{ir}}
\newcommand{\Ker}{\mathrm{Ker}}
\newcommand{\Cok}{\mathrm{Coker}}
\newcommand{\Sbf}{\mathbf{S}}
\newcommand{\low}{\mathrm{low}}
\newcommand{\Sp}{\mathrm{Sp}}
\newcommand{\Rng}{\mathrm{Rng}}
\newcommand{\vN}{\mathrm{vN}}
\newcommand{\Ebf}{\mathbf E}
\newcommand{\Nbf}{\mathbf N}
\newcommand{\Stb}{\mathrm {Stb}}
\newcommand{\SXb}{{S_{\fk X_b}}}
\newcommand{\pr}{\mathrm {pr}}
\newcommand{\SXtd}{S_{\wtd{\fk X}}}
\newcommand{\univ}{\mathrm {univ}}
\newcommand{\vbf}{\mathbf v}
\newcommand{\ubf}{\mathbf u}
\newcommand{\wbf}{\mathbf w}
\newcommand{\CB}{\mathrm{CB}}
\newcommand{\Perm}{\mathrm{Perm}}
\newcommand{\Orb}{\mathrm{Orb}}
\newcommand{\Lss}{{L_{0,\mathrm{s}}}}
\newcommand{\Lni}{{L_{0,\mathrm{n}}}}
\newcommand{\UPSU}{\widetilde{\mathrm{PSU}}(1,1)}
\newcommand{\Sbb}{{\mathbb S}}
\newcommand{\Gc}{\mathscr G_c}
\newcommand{\Obj}{\mathrm{Obj}}
\newcommand{\bpr}{{}^\backprime}
\newcommand{\fin}{\mathrm{fin}}
\newcommand{\Ann}{\mathrm{Ann}}
\newcommand{\Real}{\mathrm{Re}}
\newcommand{\Imag}{\mathrm{Im}}
%\newcommand{\cl}{\mathrm{cl}}
\newcommand{\Ind}{\mathrm{Ind}}
\newcommand{\Supp}{\mathrm{Supp}}
\newcommand{\Specan}{\mathrm{Specan}}
\newcommand{\red}{\mathrm{red}}
\newcommand{\uph}{\upharpoonright}
\newcommand{\Mor}{\mathrm{Mor}}
\newcommand{\pre}{\mathrm{pre}}
\newcommand{\rank}{\mathrm{rank}}
\newcommand{\Jac}{\mathrm{Jac}}
\newcommand{\emb}{\mathrm{emb}}
\newcommand{\Sg}{\mathrm{Sg}}
\newcommand{\Nzd}{\mathrm{Nzd}}
\newcommand{\Owht}{\widehat{\scr O}}
\newcommand{\Ext}{\mathrm{Ext}}
\newcommand{\Tor}{\mathrm{Tor}}
\newcommand{\Com}{\mathrm{Com}}
\newcommand{\Mod}{\mathrm{Mod}}
\newcommand{\nk}{\mathfrak n}
\newcommand{\mk}{\mathfrak m}
\newcommand{\Ass}{\mathrm{Ass}}
\newcommand{\depth}{\mathrm{depth}}
\newcommand{\Coh}{\mathrm{Coh}}
\newcommand{\Gode}{\mathrm{Gode}}
\newcommand{\Fbb}{\mathbb F}
\newcommand{\sgn}{\mathrm{sgn}}
\newcommand{\Aut}{\mathrm{Aut}}
\newcommand{\Modf}{\mathrm{Mod}^{\mathrm f}}
\newcommand{\codim}{\mathrm{codim}}
\newcommand{\card}{\mathrm{card}}
\newcommand{\dps}{\displaystyle}
\newcommand{\Int}{\mathrm{Int}}
\newcommand{\Nbh}{\mathrm{Nbh}}
\newcommand{\Pnbh}{\mathrm{PNbh}}
\newcommand{\Cl}{\mathrm{Cl}}
\newcommand{\diam}{\mathrm{diam}}
\newcommand{\eps}{\varepsilon}
\newcommand{\Vol}{\mathrm{Vol}}
\newcommand{\LSC}{\mathrm{LSC}}
\newcommand{\USC}{\mathrm{USC}}
\newcommand{\Ess}{\mathrm{Rng}^{\mathrm{ess}}}
\newcommand{\Jbf}{\mathbf{J}}
\newcommand{\SL}{\mathrm{SL}}
\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Lin}{\mathrm{Lin}}
\newcommand{\ALin}{\mathrm{ALin}}
\newcommand{\bwn}{\bigwedge\nolimits}
\newcommand{\nbf}{\mathbf n}
\newcommand{\dive}{\mathrm{div}}




\usepackage{algorithm}
\usepackage{algorithmic}


\newcommand{\OPT}{\mathrm{OPT}}



\numberwithin{equation}{problem}
% count the eqation by section countation


\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\dom}{dom}
\DeclareMathOperator{\ran}{ran}
\DeclareMathOperator{\ord}{ord}
\DeclareMathOperator{\img}{Im}
\DeclareMathOperator{\dd}{d\!}
\newcommand{\ie}{ \textit{ i.e. } }
\newcommand{\st}{ \textit{ s.t. }}


\usepackage[numbered,framed]{matlab-prettifier}
\lstset{
  style              = Matlab-editor,
  captionpos         =b,
  basicstyle         = \mlttfamily,
  escapechar         = ",
  mlshowsectionrules = true,
}

\usepackage[thehwcnt = 1]{iidef}
\thecourseinstitute{Tsinghua University}
\thecoursename{Discrete Optimistic}
\theterm{Fall 2024}
\hwname{Homework}
\usepackage{geometry}
\geometry{left=1.5cm,right=1.5cm,top=2.5cm,bottom=2.5cm}
\begin{document}

\courseheader
\name{Lin Zejin}
\rule{\textwidth}{1pt}
\begin{itemize}
\item {\bf Collaborators: \/}
  I finish this homework by myself. 
%   If you finish your homework all by yourself, make a similar statement. If you get help from others in finishing your homework, state like this:
%   \begin{itemize}
%   \item 1.2 (b) was solved with the help from \underline{\hspace{3em}}.
%   \item Discussion with \underline{\hspace{3em}} helped me finishing 1.3.
%   \end{itemize}
\end{itemize}
\rule{\textwidth}{1pt}

\vspace{2em}
 
\sloppy
\pagenumbering{arabic}

\begin{problem}
    If  $ d_j $ is the sequence  $ -1,1,2,3,4,4 $, then all of this are legal. However, first if  we choose   $ d_1=-1 $, now none of  $ d_2\sim d_5 $ is available, which is what the algorithm will find, \ie   $ S=\{1,6\} $. However,  $ S=\{2,3,4,5\} $ is a larger viewable set. So the algorithm is not correct.
    
    Denote  $ \OPT[j] $ as the size of optimal solution among  $ d_j,d_{j+1},\cdots,d_n $. Then the Bellman equation will be 
    \[\OPT[j]=\min_{t \text{ reachable from  $ j $ }}\{\OPT[j+1],\OPT[t]+1\}\]  
    where  $ \OPT[n]=1 $. The detail is below:
    \begin{algorithm}
        \begin{algorithmic}[1]
            \STATE  $ \OPT[n]=1 $.
            \FOR{ $ j $ from  $ n-1 $ to  $ 1 $ }
                \STATE  $ \OPT[j]=\min_{t \text{ reachable from  $ j $ }}\{\OPT[j+1],\OPT[t]+1\} $. 
            \ENDFOR
            \RETURN  $ \OPT[1] $ 
        \end{algorithmic}
    \end{algorithm} 
\end{problem}
\begin{problem}
    Denote  $ \OPT[i] $ as the minimum number of rounds when the node  $ i $ call all his subordinates (do not need direct subodinates)
    
    If node  $ i  $ has direct subordinates  $ j_1,\cdots,j_k $, WLOG we asume  $ \OPT[j_1] \geq \OPT[j_2] \geq \cdots \geq \OPT[j_k] $  
    Then easy to comfirm that the Bellman equation is like 
    \[\OPT[i]=\max_{1 \leq t \leq k}\{\OPT[t]+t\}\]
    So the algorithm will be 
    \begin{algorithm}
        \caption{ $ \OPT(i) $ }
        \begin{algorithmic}[1]
            \STATE compute $ \OPT[j]=\OPT(j) $ for each  $ j $ direct subordinate of  $ i $
            \STATE sort  $ \OPT[j] $ decreasingly. Obtain  $ \mathrm{opt}_1,\cdots,\mathrm{opt}_k $.
            \STATE  $\dps \OPT[i]=\max_{1 \leq t \leq k}\{\OPT[t]+t\} $ 
        \end{algorithmic}
    \end{algorithm} 
    The answer is  $ \OPT(n) $ where  $ n $ is the root node.  
\end{problem}
\begin{problem}
    Denote  $ \OPT[n][k] $ as  the maximum possible return of  $ k $-shot strategy  in  $ 1\sim n $ days.
    
    The Bellman equation will be 
    \[\OPT[n][k]=\min\{\OPT[n-1][k],\min_{1 \leq j \leq n-1}\{\OPT[j-1][k-1]+p[n]-p[j]\}\}\]
    in which the first term is the case that we do not sell on the last day and the second term is the case that we sell on the last day.

    So the algorithm will be 

    \begin{algorithm}
        \caption{$ \OPT $}
        \begin{algorithmic}[1]
            \FOR{ $ j $ from  $ 0 $ to  $ n $,  $ t $ from  $ 0 $ to  $ k $ }
            \IF{ $ j=0 $ \OR  $ t=0 $ }\STATE $ \OPT[j,t]\leftarrow0 $  \ENDIF 
            \STATE $ \OPT[j,t]\leftarrow\min\{\OPT[j-1,t],\min_{1 \leq l \leq n-1}\{\OPT[l-1,t-1]+p[j]-p[l]\}\} $ 
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}

    The answer is  $ 1000\times \OPT(n,k) $ and  the time complexity is  $ O(n^2k) $. The actual   $ k $-shot strategy can be given by tracing the choice of each state  $ (n,k) $.  
\end{problem}
\begin{problem}
    Denote  $ \OPT[n][H] $ as the maximum total grade,  given the functions  $ f_1,\cdots,f_n $ and total hours  $ H $.
    
    We can enumerate the hours spending on the last project to obtain a Bellman equation 
    \[\OPT[n][H]=\max_{0 \leq j \leq H}\OPT[n-1][H-j]+f_n(j)\]
    Then there is an possible algorithm that has time complexity  $ O(nH) $.
    
    \begin{algorithm}
        \caption{$ \OPT $}
        \begin{algorithmic}[1]
            \FOR{ $ k $ from  $ 0 $ to  $ n $,  $ t $ from  $ 0 $ to  $ H $ }
            \IF{ $ k=0 $ \OR  $ t=0 $ }\STATE $ \OPT[k,t]\leftarrow0 $  \ENDIF 
            \STATE  $ \OPT[k,t]\leftarrow 0 $ 
            \FOR{ $ l $ from  $ 0 $ to  $ t $}
                \IF{ $ \OPT[k,t] \leq \OPT[k-1,t-j]+f_k(j) $}
                    \STATE $ \OPT[k,t]\leftarrow \OPT[k-1,t-j]+f_k(j)$
                    \STATE  $ \mathrm{REC}[k,t]=j $.
                \ENDIF 
            \ENDFOR 
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}
    
    Then  $ \frac{1}{n}\OPT[n,H] $ is the maximum average grades and  $ \mathrm{REC}[k,t] $ is the spending hours at project  $ k $   
    at the state of  $ (k,t) $, so we can decide the hours that spend on each project by tracing it.
    
    The time complexity is  $ O(H^2n) $ 
\end{problem}
\begin{problem}
    \begin{enumerate}[label=(\alph*)]
        \item Indeed, we can prove every schedule can be scheduled in increasing order of their deadlines.
        
        If jobs  $ (s_i,s_i+t_i) $ is a proper schedule, and  $ s_1<s_1+t_1 \leq s_2<s_2+s_2 \leq \cdots \leq s_k<s_k+t_k $. Assume  $ d_i>d_{i+1} $. Then 
        \[s_i<s_i+t_i \leq s_{i+1}<s_{i+1}+t_{i+1} \leq d_{i+1}<d_i\]
        Therefore
        \[s_i<s_i+t_{i+1}=s_i+t_{i+1} \leq s_i+t_i+t_{i+1}<d_i\]
        since  $ d_i>s_{i+1}+t_{i+1} \geq s_i+t_i+t_{i+1} $.
        
        So  we can exchange the order of job  $ i $, $ i+1 $. By Bubble sort algorithm, we can obtain an available schedule that execute in increasing order of their deadlines.

        \item We only need to consider the schedule that execute in increasing order of their deadlines.
        Denote  $ \OPT[n][D] $ as the optimal size of jobs $ 1,2,\cdots,n $  and final dealines  $ D $.

        WLOG, we may assume  $ d_1 \leq d_2 \leq \cdots \leq d_n $.
        Each time we consider whether we choose job  $ n $ or not. Since job  $ n $ has the last deadlines in that state, we can arrange for it to be the last to   execute. So the Bellman equation is 
        \[\OPT[n][D]=\begin{cases}
            0&t_n>\min\{d_n,D\}\\
            \max\{\OPT[n-1][D],\OPT[n-1][\min\{d_n,D\}-t_n]+1\}
        \end{cases}\]  
    \end{enumerate}
    So the algorithm is 
    
    \begin{algorithm}
        \caption{$ \OPT $}
        \begin{algorithmic}[1]
            \FOR{ $ k $ from  $ 0 $ to  $ n $,  $ t $ from  $ 0 $ to  $ D $ }
            \IF{ $ k=0 $ \OR  $ t=0 $ \OR  $ t_k>\min\{d_k,t\} $ }\STATE $ \OPT[k,t]\leftarrow0 $  \ENDIF 
            \STATE  $ \OPT[k,t]\leftarrow \OPT[k-1,t] $.
            \STATE  $ \mathrm{REC}[k,t]=0 $.
            \IF{ $ \OPT[k,t]<\OPT[k-1][\min\{d_k,t\}-t_k]+1 $ }
                \STATE     $ \OPT[k,t]\leftarrow\OPT[k-1][\min\{d_k,t\}-t_k]+1 $
                \STATE  $ \mathrm{REC}[k,t]=1 $.
            \ENDIF 
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}


    Then  $ \OPT[n,D] $ is the optimal solution and  $ \mathrm{REC}[k,t] $ marks the choice in the state  $ (k,t) $ which can be traced to form a available schedule.
    
    Its time complexity is  $ O(nD) $ 
\end{problem}
\begin{problem}
    In the lecture we find its Bellman equation 
    \[\OPT[i,j]=\min\begin{cases}
    \OPT[i-1,j-1]+\alpha_{a_ib_j}\\
    \OPT[i-1,j]+\delta\\
    \OPT[i,j-1]+\delta
\end{cases}\]
It involves all possible cases, so it suffices to mark all possible choices in the state  $ (i,j) $.

We define a function  $ mark[i,j]  $ with 
\[mark[i,j]=\begin{cases}
    1&\text{ if }\begin{cases}
        \OPT[i-1,j-1]+\alpha_{a_ib_j}\\
        \OPT[i-1,j]+\delta\\
        \OPT[i,j-1]+\delta
    \end{cases} \text{has two possible choices of minimum}\\
    0&\text{otherwise}
\end{cases}\]
which can be traced in the process of DP.

So after DP in  $ O(nm) $,  we obtain a possible minimum-cost alignment. Compared with the proposed alignment, we know whether it is optimal or not. And trace all the choices in this alignment and check whether  $ marh[i,j] $ is 1 or not in each state, we can find whether it is unique or not. 
\end{problem}
\begin{problem}
    \newcommand{\Is}{\mathrm{IsInter}}
    Denote  $ \Is[k][i][j] $ as the possibility if the first  $ k $ characters of  $ s $  can be partitioned into  two subsequences  $ s_1 $ and  $ s_2 $  so that  $ s_1 $ is a repetition  of  $ x $ and  $ s_2 $ is a repetition of  $ y $, moreover  \[\mathrm{len}(s_1)\equiv i \mod \mathrm{len}(x),\qquad\mathrm{len}(s_2)\equiv j\mod \mathrm{len}(y) \]

    For example,  $ \Is[1][i][j]=\begin{cases}
        1&(i,j)=(1,j)\text{ and }s[1]=x[1]\\
        1&(i,j)=(i,1)\text{ and }s[1]=y[1]\\
        0&\text{otherwise}
    \end{cases} $.

    The Bellman equation is 
    \begin{equation}\label{eq1}
        \Is[k][i][j]=\begin{cases}
            \max\left\{\Is[k-1][i-1][j],\Is[k-1][i][j-1]\right\}&\text{if  $ s[k]=x[i] $ and $ s[k]=y[j] $}\\
            \Is[k-1][i-1][j]&\text{else if  $ s[k]=x[i] $}\\
            \Is[k-1][i][j-1]&\text{else if  $ s[k]=y[j] $}\\
            0&\text{otherwise}
        \end{cases}
    \end{equation}
    because the  $ k $-th character have two choice. In \eqref{eq1},  $ i-1 $,  $ j-1 $ is chosen to be the one in $ \{1,2,\cdots,\mathrm{len}(x)\},\{1,2,\cdots,\mathrm{len}(y)\} $ under the module meaning respectively.
    
    So the algorithm can be implemented as follows
    \begin{algorithm}
        \begin{algorithmic}[1]
            \STATE  $ l_x=\mathrm{len}(x),l_y=\mathrm{len}(y),n=\mathrm{len}(s) $.
            \STATE  $ \Is[0][i][j]\leftarrow
            \begin{cases}
                1&(i,j)=(l_x,l_y)\\
                0&\text{otherwise}
            \end{cases} $ 
            \FOR{ $ k $ from  $ 2 $ to  $ n $, $ i $ from  $ 1 $ to  $ l_x $,  $ j $ from  $ 1 $ to  $ l_y $    }
                \IF{ $ i=1 $}\STATE  $ i'=l_x $   \ELSE  \STATE$ i'=i-1 $ \ENDIF
                \IF{ $ j=1 $}\STATE  $ j'=l_y $   \ELSE  \STATE$ j'=j-1 $ \ENDIF
                \STATE  $ \Is[k][i][j]\leftarrow0 $ 
                \IF{ $ s[k]=x[i] $ and  $ \Is[k-1][i'][j]=1 $}
                    \STATE  $ \Is[k][i][j]\leftarrow1 $.
                \ENDIF 
                \IF{ $ s[k]=y[j] $ and  $ \Is[k-1][i][j']=1 $}
                    \STATE  $ \Is[k][i][j]\leftarrow1 $.
                \ENDIF
            \ENDFOR
        \end{algorithmic}
    \end{algorithm}
    The answer is  $ \max_{i,j} \Is[n][i][j] $. 

    Since we can delete all data after two iterations, the space complexity is  $ O(l_xl_y) $, and the time complexity is  $ O(nl_xl_y) $  which is a polynomial algorithm. 
\end{problem}

\begin{problem}
    WLOG we can normalize  $ r_i $ such that  $ r_{min}=1 $.

    (a) Noticed that 
    \[R(S)=\frac{\sum_{i\in S}r_iv_i}{1+\sum_{i\in S}v_i}=\frac{\sum_{i\in S}(r_i\cdot\frac{v_i}{v_i+\frac{1}{|S|}})(v_i+\frac{1}{|S|})}{\sum_{i\in S}v_i+\frac{1}{|S|}} \in\left( \min_{i\in S,|S| \leq K}\left\{r_i\cdot\frac{v_i}{v_i+\frac{1}{|S|}}\right\}, \max_{i\in S,|S| \leq K}\left\{r_i\cdot\frac{v_i}{v_i+\frac{1}{|S|}}\right\}\right)\overset{\triangle }{=}(a,b)\]
    with  $ 0<a<b \leq r_{max}=\frac{r_{max}}{r_{min}} $. 

    It suffices to find the maximal possible value of  $ R(S) $ in  $ (a,b) $.  

    For each  $ r\in (a,b) $, 
    \begin{align}
        \exists S,|S| \leq K,R(S) \geq r&\Leftrightarrow\sum_{i\in S}(r_i-r)v_i \geq r\notag\\
        &\Leftrightarrow \text{  $ \exists(r_{i_1}-r)v_{i_2} \geq (r_{i_2}-r)v_{i_2} \geq \cdots \geq (r_{i_t}-r)v_{i_t} \geq 0 $ such that  $ \dps\sum_{k=1}^t (r_{i_k}-r)v_{i_k} \geq r $ and  $ t \leq K $} \label{eq2}
    \end{align}


    The last circumstance only needs to sort  $ (r_i-r)v_i $ and calculate the first  $ K $-th  sum, (or the sum of  all positive value $ (r_i-r)v_i $) which costs time complexity  $ O(N\log N) $. The function is 
    \begin{algorithm}
        \caption{IsLargeThanOPT($r$)}
        \label{alg1}
        \begin{algorithmic}
            \STATE sort  $ (r_i-r)v_i $.
            \STATE  $ \mathrm{sum}\leftarrow0 , S\leftarrow\emptyset$ 
            \FOR{ $ i $  from  $ 1 $ to  $ K $}
                \IF{ $ (r_i-r)v_i>0 $ }
                    \STATE  $ \mathrm{sum}\leftarrow\mathrm{sum}+(r_i-r)v_i $.
                    \STATE  $ S\leftarrow S\cup\{i\} $
                \ENDIF
            \ENDFOR
            \IF{ $ \mathrm{sum}\geq r $} 
                \RETURN FALSE and the set  $ S $
            \ELSE \RETURN TRUE
            \ENDIF 
        \end{algorithmic}
    \end{algorithm}
    
    To determine  $ R(S^*) $, we can use bisection method:
    
    \begin{algorithm}
        \caption{General algorithm}
        \label{alg2}
        \begin{algorithmic}[1]
            \STATE Determines  $ a_0\leftarrow a,b_0\leftarrow b,i\leftarrow 1 $.
            \WHILE{}\label{1}
                \STATE  $ r_i\leftarrow \frac{a_{i-1}+b_{i-1}}{2} $
                \IF{IsLargeThanOPT($r$)=FALSE}
                    \STATE RETURN a possible  $ S $ with  $ |S| \leq K $ such that  $ R(S) \geq r $.
                    \STATE  $ a_i\leftarrow r_i,b_i\leftarrow b_{i-1} $.
                \ELSIF{ $ r_i \geq R(S^*) $ }
                    \STATE  $ a_i\leftarrow a_{i-1},b_i\leftarrow r_i $.
                \ENDIF
            \ENDWHILE 
        \end{algorithmic}
    \end{algorithm}
    After  $ t $ times of  WHILE iterations \ref{1}, we can find a  $ r $ such that  $\dps r-R(S^*) \leq \frac{b-a}{2^t} $.
    
    So after iterations in  $ O(\log \frac{b-a}{\epsilon}) $, we can find a  $ r_i\in (a_i,b_i) $ within  $ (1\pm \epsilon) $-factor of  $ R(S^*) $ (as  $ \epsilon\rightarrow 0 $) 

    Then  $ a_i \leq S(R^*) $ satisfies that  $ \exists S, |S| \leq K $,  $ R(S) \geq (1-\epsilon)R(S^*) $, given by the process of Algorithm \ref{alg1}
    
    Since each iteration cost  $ O(N\log N) $, the total time complexity will be 
    \[O(N\log N)\cdot O(\log\frac{b-a}{\epsilon})=O(N\log N\log\frac{r_{max}}{r_{min}}+N\log N\log\epsilon^{-1})\] 

    (b,c) We still use  algorithm \ref{alg2} to find  $ r $. It suffices to determine the function  $ IsLargeThanOPT(r)   $.
      
    It is equivalent to solve \eqref{eq2}, which  is a knapsack problem. 
    
    (b) However, under the condition of (b), we can use  a Weight-Based DP such that the time  complexity of  $ IsLargeThanOPT(r) $ is  $ O(nW) $. Then  the total time complexity will be  $ O(NW)\cdot O(\log\frac{b-a}{\epsilon})=O(NW\log\frac{r_{max}}{r_{min}}+NW\log\epsilon^{-1}) $.  

    (c) In the lecture we find an algorithm in time complexity of  $ O(N^3\epsilon^{-1}) $ to find the solution  $ S $ such that  $ R(S) \geq (1-\frac{\epsilon}{2})R(S^*) $. So in  $ O(N^3\epsilon^{-1}) $, we can define a function  $ IsLargeThanOPT(r) $ to determine whether  $ r \geq (1-\frac{\epsilon}{2})R(S^*) $ or not.   
    
    After iterations in  $ O(\log \frac{b-a}{\epsilon}) $, we can find a  $ r_i\in (a_i,b_i) $ within  $ (1\pm \frac{\frac{\epsilon}{2}}{1-\frac{\epsilon}{2}}) $-factor of  $ (1-\frac{\epsilon}{2})R(S^*) $ (as  $ \epsilon\rightarrow 0 $)  

    Then  $ a_i \leq S(R^*) $ satisfies that  $ \exists S, |S| \leq K $,  $ R(S) \geq (1-\epsilon)R(S^*) $, given by the process of the knapsack valued-based FPTAS

    The time complexity will be 
    \[O(N^3\epsilon^{-1})\cdot O(\log\frac{b-a}{\epsilon})=O(N^3\epsilon^{-1}\log\frac{r_{max}}{r_{min}}+N^3\epsilon^{-1}\log\epsilon^{-1})\]
    which is a FPTAS.

    
\end{problem}




\end{document}